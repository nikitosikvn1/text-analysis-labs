{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8352a9ab-cfa4-46ca-9083-382d2268f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from pprint import pprint\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b7b3b-9651-4928-bb41-336ca50c0c2e",
   "metadata": {},
   "source": [
    "### Loading JSON data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec54fe1f-0d76-4d60-8867-a64091b13c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/services.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7f2b7-5290-4cb1-8c5e-b2c6ac2468a0",
   "metadata": {},
   "source": [
    "### Extracting doctor names using Spacy Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbf64d2-6521-4a6d-808d-dc7bb21cdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doctor_name_pattern = [\n",
    "    [{\"LOWER\": {\"IN\": [\"dr.\", \"dr\", \"doctor.\", \"doctor\"]}}, {\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\", \"OP\": \"*\"}],\n",
    "]\n",
    "\n",
    "matcher.add(\"DOCTOR_NAME\", doctor_name_pattern)\n",
    "\n",
    "def extract_doctor_names(text):\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    doctor_names = [doc[start:end].text for match_id, start, end in matches]\n",
    "    return doctor_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef06aa-4900-4007-bd2a-5cd81b2677b3",
   "metadata": {},
   "source": [
    "### Display all matches found in services.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d29be6-eed4-4aac-9557-3561d153d357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dr Oscar', 'Dr Oscar Ventanilla', 'Dr Pucan', 'Dr Pucan Dental',\n",
      " 'Dr Pucan Dental Office', 'Dr. Andrei', 'Dr. Andrei Simel', 'Dr. Azadeh',\n",
      " 'Dr. Azadeh Jafarnia', 'Dr. Brian', 'Dr. Brian W.', 'Dr. Brian W. Chun',\n",
      " 'Dr. Burk', 'Dr. Christopher', 'Dr. Christopher J.',\n",
      " 'Dr. Christopher J. Bennett', 'Dr. David', 'Dr. David I.',\n",
      " 'Dr. David I. Thompson', 'Dr. Diaz', 'Dr. Diaz F', 'Dr. Diaz F Luisa',\n",
      " 'Dr. Eugene', 'Dr. Eugene H.', 'Dr. Eugene H. Burton',\n",
      " 'Dr. Eugene H. Burton Iii', 'Dr. James', 'Dr. James A.', 'Dr. James A. Abbott',\n",
      " 'Dr. John', 'Dr. John Ichiuji', 'Dr. John Y.', 'Dr. John Y. Park',\n",
      " 'Dr. Keller', 'Dr. Kwang', 'Dr. Kwang H.', 'Dr. Kwang H. Kim', 'Dr. Lawrence',\n",
      " 'Dr. Lawrence J.', 'Dr. Lawrence J. Mcdonald', 'Dr. Maria',\n",
      " 'Dr. Maria Theresa', 'Dr. Maria Theresa V.', 'Dr. Maria Theresa V. Chua',\n",
      " 'Dr. Michael', 'Dr. Michael K.', 'Dr. Michael K. Singh', 'Dr. Pascuala',\n",
      " 'Dr. Pascuala Geraldine', 'Dr. Pascuala Geraldine T.',\n",
      " 'Dr. Pascuala Geraldine T. Ocampo', 'Dr. Pedram', 'Dr. Pedram Malek',\n",
      " 'Dr. Peter', 'Dr. Peter Han', 'Dr. Robert', 'Dr. Robert S.',\n",
      " 'Dr. Robert S. Gilbert', 'Dr. Sethi', 'Dr. Sridevi', 'Dr. Sridevi Alapati',\n",
      " 'Dr. Stephen', 'Dr. Stephen T.', 'Dr. Stephen T. Fan', 'Dr. Virdi'}\n"
     ]
    }
   ],
   "source": [
    "doctor_names = [\n",
    "    name\n",
    "    for dialogue in data\n",
    "    for turn in dialogue['turns']\n",
    "    if turn['speaker'] == 'SYSTEM'\n",
    "    for frame in turn['frames']\n",
    "    if 'service_results' in frame\n",
    "    for result in frame['service_results']\n",
    "    if 'dentist_name' in result\n",
    "    for name in extract_doctor_names(result['dentist_name'])\n",
    "]\n",
    "\n",
    "pprint(set(doctor_names), compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10611e-2b28-4f8d-b22f-e9e3d3768d69",
   "metadata": {},
   "source": [
    "### Extracting user confirmations with Spacy Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f2e6b7-d924-46c3-ac6f-a9c0bc3cbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "confirmation_patterns = [\n",
    "    [{\"LOWER\": {\"IN\": [\"yes\", \"yeah\", \"yep\", \"sure\", \"ok\", \"okay\", \"alright\", \"great\", \"absolutely\", \"definitely\", \"affirmative\", \"indeed\"]}}],\n",
    "    [{\"LOWER\": \"yes\"}, {\"IS_PUNCT\": True, \"OP\": \"?\"}, {\"LOWER\": \"that\"}, {\"LOWER\": \"is\"}, {\"LOWER\": {\"IN\": [\"correct\", \"right\"]}}],\n",
    "    [{\"LOWER\": \"sounds\"}, {\"LOWER\": \"good\"}],\n",
    "]\n",
    "\n",
    "matcher.add(\"CONFIRMATION\", confirmation_patterns)\n",
    "\n",
    "def extract_confirmations(text):\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    confirmations = [doc[start:end].text for match_id, start, end in matches]\n",
    "    return confirmations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44882813-e90c-4df0-b96c-0a4665dbf014",
   "metadata": {},
   "source": [
    "### Display all matches found in services.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f73372-36fa-4ee3-8f0d-7da4ea4bf2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yes that sounds good I have to make an appointment, is there anything available for 5:30 in the evening?\n",
      "Confirmation: Yes\n",
      "\n",
      "Sentence: Yes that sounds good I have to make an appointment, is there anything available for 5:30 in the evening?\n",
      "Confirmation: sounds good\n",
      "\n",
      "Sentence: Yes, that is correct.\n",
      "Confirmation: Yes\n",
      "\n",
      "Sentence: Yes, that is correct.\n",
      "Confirmation: Yes, that is correct\n",
      "\n",
      "Sentence: Great, thank you for your help.\n",
      "Confirmation: Great\n",
      "\n",
      "Sentence: Yeah I'd like to see a dentist at that one.\n",
      "Confirmation: Yeah\n",
      "\n",
      "Sentence: Yeah\n",
      "Confirmation: Yeah\n",
      "\n",
      "Sentence: Alright thank you, that's all I need.\n",
      "Confirmation: Alright\n",
      "\n",
      "Sentence: Yes, I think I'll go to them.\n",
      "Confirmation: Yes\n",
      "\n",
      "Sentence: Yes please. 1:45 PM would be perfect if there's a slot then.\n",
      "Confirmation: Yes\n",
      "\n",
      "Sentence: Yes that is right.\n",
      "Confirmation: Yes\n",
      "\n",
      "Sentence: Yes that is right.\n",
      "Confirmation: Yes that is right\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confirmations = [\n",
    "    (turn['utterance'], confirmation)\n",
    "    for dialogue in data[:4]\n",
    "    for turn in dialogue['turns']\n",
    "    if turn['speaker'] == 'USER'\n",
    "    for confirmation in extract_confirmations(turn['utterance'])\n",
    "]\n",
    "\n",
    "for utterance, confirmation in confirmations:\n",
    "    print(f\"Sentence: {utterance}\\nConfirmation: {confirmation}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b7bc7-ee47-4c31-8ecb-feb78d25248f",
   "metadata": {},
   "source": [
    "### Extracting user intent with direct objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ab67af-4223-4bd8-a2f6-c34978914c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Yes that sounds good I have to make an appointment, is there anything available for 5:30 in the evening?\n",
      "Intent: make appointment\n",
      "\n",
      "Text: Great, thank you for your help.\n",
      "Intent: thank you\n",
      "\n",
      "Text: My tooth has been hurting lately, where can I find a dentist?\n",
      "Intent: find dentist\n",
      "\n",
      "Text: Yeah I'd like to see a dentist at that one.\n",
      "Intent: see dentist\n",
      "\n",
      "Text: Book it on the 10th of March around 12:30 in the afternoon.\n",
      "Intent: book it\n",
      "\n",
      "Text: Actually, no. Book it on the 7th.\n",
      "Intent: book it\n",
      "\n",
      "Text: Do they do cosmetic services too?\n",
      "Intent: do services\n",
      "\n",
      "Text: Alright thank you, that's all I need.\n",
      "Intent: thank you\n",
      "\n",
      "Text: I've been wanting to fix my crooked teeth for a while. Can you find me a good dentist that practices cosmetic dentistry.\n",
      "Intent: fix teeth\n",
      "\n",
      "Text: I've been wanting to fix my crooked teeth for a while. Can you find me a good dentist that practices cosmetic dentistry.\n",
      "Intent: practice dentistry\n",
      "\n",
      "Text: No, I've changed my mind. Is there a slot available at quarter to 12 in the morning on the 10th?\n",
      "Intent: change mind\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utterances = [\n",
    "    turn['utterance']\n",
    "    for dialogue in data[:3]\n",
    "    for turn in dialogue['turns']\n",
    "    if turn['speaker'] == 'USER'\n",
    "    for frame in turn['frames']\n",
    "    if 'active_intent' in frame['state']\n",
    "]\n",
    "\n",
    "for text in utterances:\n",
    "    text = nlp(text)\n",
    "    for token in text:\n",
    "        if token.dep_ == \"dobj\":\n",
    "            verb, dobj = token.head, token.text\n",
    "            print(f\"Text: {text}\\nIntent: {verb.lemma_.lower()} {dobj}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
