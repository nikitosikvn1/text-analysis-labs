{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e98eda9-7fb7-4b98-8185-d702c11a7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Set, List\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1cb44-aa90-46e5-811e-05d2bf6ef0f4",
   "metadata": {},
   "source": [
    "### Suppress warnings from the `ConvergenceWarning` category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929177ee-5a25-4937-a3c2-f0de7d79374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4dd0f-7876-4ac6-a584-f7dc0c4d4f2a",
   "metadata": {},
   "source": [
    "### Load the dataset from `science.csv` into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc8759b-7294-4110-a86f-c8b368d0bd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8695 entries, 0 to 8694\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Id       8695 non-null   object\n",
      " 1   Comment  8695 non-null   object\n",
      " 2   Topic    8695 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 203.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/science.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d1b94-0ff9-4ffa-9fde-263cb4ba88e9",
   "metadata": {},
   "source": [
    "### Display the first 10 rows of the DataFrame to get a quick overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b05e20f-5372-4235-bb60-fff7b5235e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x840</td>\n",
       "      <td>A few things. You might have negative- frequen...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xbf0</td>\n",
       "      <td>Is it so hard to believe that there exist part...</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1dfc</td>\n",
       "      <td>There are bees</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xc7e</td>\n",
       "      <td>I'm a medication technician. And that's alot o...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xbba</td>\n",
       "      <td>Cesium is such a pretty metal.</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0xb39</td>\n",
       "      <td>I meant that the question itself is unclear.</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1f3d</td>\n",
       "      <td>Shove it up your ass and see what happens</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x531</td>\n",
       "      <td>??? I mean it has some butter, but besides tha...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0xe05</td>\n",
       "      <td>https://t.me/joinchat/3gElLHLuMCxhNGI0</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x2148</td>\n",
       "      <td>Well, that’s just the thing. You can’t really ...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                            Comment      Topic\n",
       "0   0x840  A few things. You might have negative- frequen...    Biology\n",
       "1   0xbf0  Is it so hard to believe that there exist part...    Physics\n",
       "2  0x1dfc                                     There are bees    Biology\n",
       "3   0xc7e  I'm a medication technician. And that's alot o...    Biology\n",
       "4   0xbba                     Cesium is such a pretty metal.  Chemistry\n",
       "5   0xb39       I meant that the question itself is unclear.  Chemistry\n",
       "6  0x1f3d          Shove it up your ass and see what happens    Biology\n",
       "7   0x531  ??? I mean it has some butter, but besides tha...  Chemistry\n",
       "8   0xe05             https://t.me/joinchat/3gElLHLuMCxhNGI0    Biology\n",
       "9  0x2148  Well, that’s just the thing. You can’t really ...    Biology"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f15ba-c839-4638-8ec5-e49a2bd8e46d",
   "metadata": {},
   "source": [
    "### Count the occurrences of each unique value in the `Topic` column (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "864a1738-3154-4fb8-b06c-bba94f32e8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "Biology      3591\n",
       "Chemistry    2920\n",
       "Physics      2184\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84a356-d1a1-49f3-9c55-2f18fce29e0f",
   "metadata": {},
   "source": [
    "### Define a function `preprocess_text` to clean and preprocess text data\n",
    "#### Apply this function to the `Comment` column to remove punctuation, lowercase all text, and filter out stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb57038-3c08-496c-90b6-90de74175bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x840</td>\n",
       "      <td>things might negative frequency dependent sele...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xbf0</td>\n",
       "      <td>hard believe exist particulars cant detect any...</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1dfc</td>\n",
       "      <td>bees</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xc7e</td>\n",
       "      <td>im medication technician thats alot drugs live...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xbba</td>\n",
       "      <td>cesium pretty metal</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0xb39</td>\n",
       "      <td>meant question unclear</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1f3d</td>\n",
       "      <td>shove ass see happens</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x531</td>\n",
       "      <td>mean butter besides sugar baking soda peanuts ...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0xe05</td>\n",
       "      <td>httpstmejoinchatgellhlumcxhngi</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x2148</td>\n",
       "      <td>well thats thing cant really induce immune res...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                            Comment      Topic\n",
       "0   0x840  things might negative frequency dependent sele...    Biology\n",
       "1   0xbf0  hard believe exist particulars cant detect any...    Physics\n",
       "2  0x1dfc                                               bees    Biology\n",
       "3   0xc7e  im medication technician thats alot drugs live...    Biology\n",
       "4   0xbba                                cesium pretty metal  Chemistry\n",
       "5   0xb39                             meant question unclear  Chemistry\n",
       "6  0x1f3d                              shove ass see happens    Biology\n",
       "7   0x531  mean butter besides sugar baking soda peanuts ...  Chemistry\n",
       "8   0xe05                     httpstmejoinchatgellhlumcxhngi    Biology\n",
       "9  0x2148  well thats thing cant really induce immune res...    Biology"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str, stop_words: Set[str]) -> str:\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, flags=re.IGNORECASE).lower().strip()\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    filtered_tokens = [t for t in tokens if t not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "stoplist = set(stopwords.words('english'))\n",
    "df['Comment'] = df['Comment'].apply(lambda doc: preprocess_text(doc, stoplist))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b7f25-4b0d-4fcd-8170-feefa2c97bf8",
   "metadata": {},
   "source": [
    "### Remove rows where the `Comment` column is empty after preprocessing, and drop any rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3262b6fc-8b6e-4690-b06d-3765c2615197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8642"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~(df['Comment'].str.strip() == '')]\n",
    "df.dropna(inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38885b-92e1-4f1e-ab37-127514511393",
   "metadata": {},
   "source": [
    "### Encode the `Topic` column with numerical labels and convert the `Comment` column into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f976712-7e9a-49d2-aad3-c6f2a7288814",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['Topic'] = label_encoder.fit_transform(df['Topic'])\n",
    "df['Comment'] = df['Comment'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182adbc-b341-43c9-aa62-8181b615490e",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing sets with an 80-20 split for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "647b00a0-79f9-40aa-a128-3151b6934388",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, labels = df['Comment'], df['Topic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c531d4-78ef-44eb-bbb6-96ab240ed6cb",
   "metadata": {},
   "source": [
    "### Set parameters for training a Word2Vec model and train it on the comments from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51addf8f-a7d2-47f1-99de-846d5fd49277",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_params = {\n",
    "    'vector_size': 1000,\n",
    "    'window': 100,\n",
    "    'min_count': 2,\n",
    "    'sg': 1,\n",
    "    'sample': 1e-3,\n",
    "    'workers': 8,\n",
    "}\n",
    "\n",
    "w2v_model = Word2Vec(X_train, **w2v_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b7b59e-7f0e-4fc7-af8e-91b62907a714",
   "metadata": {},
   "source": [
    "### Define a function `document_vectorizer` to convert lists of words into fixed-size vectors by averaging the Word2Vec vectors of the words in a document\n",
    "#### Apply this function to both the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384d4de6-ac2c-424a-abdc-4f5582eb163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model:\n",
      "Train features shape: (6913, 1000)\n",
      "Test features shape: (1729, 1000)\n"
     ]
    }
   ],
   "source": [
    "def document_vectorizer(corpus: List[List[str]], model: Word2Vec, num_features: int) -> np.ndarray:\n",
    "    vocab = set(model.wv.index_to_key)\n",
    "    \n",
    "    def mean_words_vectors(words: List[str], model: Word2Vec, vocab: Set[str], num_features: int) -> np.ndarray:\n",
    "        words = [word for word in words if word in vocab]\n",
    "        if not words:\n",
    "            return np.zeros((num_features,), dtype=\"float32\")\n",
    "        \n",
    "        feature_vectors = np.array([model.wv[word] for word in words])\n",
    "        feature_vector = feature_vectors.mean(axis=0)\n",
    "        return feature_vector\n",
    "\n",
    "    features = np.array([mean_words_vectors(s, model, vocab, num_features) for s in corpus])\n",
    "    return features\n",
    "\n",
    "mean_train_features = document_vectorizer(X_train, w2v_model, 1000)\n",
    "mean_test_features = document_vectorizer(X_test, w2v_model, 1000)\n",
    "\n",
    "print(f'Word2Vec model:\\n\\\n",
    "Train features shape: {mean_train_features.shape}\\n\\\n",
    "Test features shape: {mean_test_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46940577-d280-4a22-a782-497c43f686ce",
   "metadata": {},
   "source": [
    "### Train a logistic regression classifier on the vectorized training data and evaluate its accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d2d8b0a-adfd-446b-959d-d58fae86e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized Logistic Regression accuracy: 0.626951995373048\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(mean_train_features, y_train)\n",
    "lr_pred = lr_classifier.predict(mean_test_features)\n",
    "\n",
    "print(f'Unoptimized Logistic Regression accuracy: {accuracy_score(y_test, lr_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ce38f-bae7-4368-b289-3218522104fd",
   "metadata": {},
   "source": [
    "### Train a random forest classifier on the vectorized training data and evaluate its accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc3cc60-2a0f-44a0-8093-5e4fc5dad51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized Random Forest Classifier accuracy: 0.6674378253325621\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "rf_classifier.fit(mean_train_features, y_train)\n",
    "rf_pred = rf_classifier.predict(mean_test_features)\n",
    "\n",
    "print(f'Unoptimized Random Forest Classifier accuracy: {accuracy_score(y_test, rf_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421c3a0-b529-44fd-b1d3-2041cc34041b",
   "metadata": {},
   "source": [
    "### Perform a grid search to find the best hyperparameters for the logistic regression model based on accuracy, using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5bcb8e-66e9-4bfc-9ef7-827945777d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nikitap/.cache/pypoetry/virtualenvs/text-analysis-labs-dvW6NfsW-py3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1000.0, 'solver': 'newton-cg'}\n",
      "Best accuracy: 0.6625200778943822\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(-3,3,7),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_search.fit(mean_train_features, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87255157-dd38-412e-85dc-7d953da346d7",
   "metadata": {},
   "source": [
    "### Perform a grid search to find the best hyperparameters for the random forest classifier based on accuracy, using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1469cea5-8f9e-45d4-a399-e760f4261090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best accuracy: 0.6726463475759508\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_search.fit(mean_train_features, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
